{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling-up Deep Learning Inference to Large-Scale Bioimage Data (part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact info:\n",
    "- Fernando Cervantes\n",
    "- Systems Analyst in JAX's Research IT\n",
    "- email: fernando.cervantes@jax.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. [Optional] Convert a Tiff into Zarr format with `bioformats2raw`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a terminal (e.g. from the Launcher) and use the following command:\n",
    "\n",
    "```\n",
    "bioformats2raw CMU-1_Crop.ome.tif CMU-1_Crop.ome.zarr --use-existing-resolutions -p\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, download the pre-converted image from [here](https://drive.google.com/file/d/1BmNxOrO3vOFPR-PCnV00DYgFsD1sDu47/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U52nK_GJ3ta"
   },
   "source": [
    "---\n",
    "# 2. Compute on Zarr arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Set up a Dask cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Use the Jupyter's Dask extension to start a distributed cluster\n",
    "- [ ] Click the \"+ New\" button at the bottom of the plugin\n",
    "\n",
    "![image](dask_extension.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Click the \"<>\" button to inject the code needed to connect with this cluster\n",
    "\n",
    "![image](dask_extension_ready.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1721423554002,
     "user": {
      "displayName": "Fernando Cervantes",
      "userId": "15218495656973493127"
     },
     "user_tz": 240
    },
    "id": "V08qIEwUg31f"
   },
   "outputs": [],
   "source": [
    "import zarr\n",
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change this to the actual path where the image is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"C:\\Users\\Public\\Documents\\WSI_example\\CMU-1_Crop.ome.zarr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. [Example] Segmentation of nuclei in WSI (Cellpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Load the `cyto3` pre-trained model from Cellpose library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9131,
     "status": "ok",
     "timestamp": 1721232009022,
     "user": {
      "displayName": "Fernando Cervantes",
      "userId": "15218495656973493127"
     },
     "user_tz": 240
    },
    "id": "IT4-AHyZ9Y2W",
    "outputId": "913325bc-f985-420d-8f15-e7dcc3835e81"
   },
   "outputs": [],
   "source": [
    "from cellpose import models, transforms\n",
    "import torch\n",
    "\n",
    "gpu = torch.cuda.is_available()\n",
    "model_type = \"cyto3\"\n",
    "\n",
    "cellpose_model = models.CellposeModel(gpu=gpu, model_type=model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.1 Compute as numpy array (`.compute()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = transforms.convert_image(da_sel.compute(), channel_axis=2, channels=[0, 0])\n",
    "img_t = transforms.normalize_img(img_t, invert=False, axis=2)\n",
    "\n",
    "labels, _, _ = cellpose_model.eval(img_t[None, ...], diameter=None, flow_threshold=None, channels=[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRTdgTzi_KfU"
   },
   "outputs": [],
   "source": [
    "plt.imshow(da_sel)\n",
    "plt.imshow(skimage.color.label2rgb(labels), alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bI1MVE59WVg5"
   },
   "source": [
    "---\n",
    "## 3.2 Compute the segmentation lazily with Dask (`delayed`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Define the inference pipeline as a function that can be applied to an image chunk\n",
    "- [ ] Use `dask.delayed` to convert it into a lazy function\n",
    "- [ ] Create a `dask.array` from the delayed output of the lazy function with `dask.array.from_delayed` (`da.from_delayed`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kzn30hw9Iur0"
   },
   "source": [
    "---\n",
    "## 3.3 Distribute computation with `map_blocks`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Use the `dask.array.map_blocks` (`da.map_blocks`) function to apply the inference pipeline to the whole image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Create an overlay of the labels generated by the inference pipeline on top of the image pixels. Use 'skimage.color.label2rgb', but this will require to use `.compute()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Use the `.blocks` property of `dask.array`s to access the pixels with a chunk/block-based coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pntbbzQ9Jus-"
   },
   "source": [
    "---\n",
    "## 3.4 Debug `map_blocks` computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Show the Log Console and change the log level to \"Info\"\n",
    "- [ ] Import the replacement of the `print` function from `dask.distributed`. Import it as `dask_print` to prevent issues with the regular `print` function\n",
    "- [ ] Test what happens when we don't use `drop_axis` argument in `dask.array.map_blocks` (`da.map_blocks`)\n",
    "- [ ] Add a `dask_print` statement in `cellpose_segment` function to investigate what is the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import print as dask_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2cwPMwbLjMv"
   },
   "source": [
    "---\n",
    "## 3.5 Return arrays with different shape with `map_blocks`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Add a post-processing step to convert the outputs from the segmentation pipeline into a set of region properties (`skimage.measure.regionprops`)\n",
    "    - Note that now the output of this function is a $1\\times1$ array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqwgESbk-igb"
   },
   "source": [
    "---\n",
    "# 4. [Example] Compute on masked chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lf5o7b4BN0Ko"
   },
   "source": [
    "## 4.1 Compute a mask from a low-resolution level of the input *pyramid*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Compute a low-resolution mask using image processing\n",
    "  - Use the downsampled image at level $2$ from input .zarr file (\"0/2\")\n",
    "  - Convert the color image into grayscale\n",
    "  - Smooth the image and apply a fixed threshold on all chunks\n",
    "  - Downscale the mask to represent a $512\\times512$ pixels region with a single pixel of the mask with an aggregation function (i.e. `.sum()`, `.mean()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GvxLxscNq-_"
   },
   "source": [
    "---\n",
    "# 5. [Exercise] Reduce computations on map_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1  Apply the deep learning segmentation pipeline only on masked regions of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Add a verification step to determine whether the current image chunk should be processed or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5B6f7W1NOg3C"
   },
   "source": [
    "---\n",
    "## 5.2 Store the segmentation as a Zarr file on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Use the `.to_zarr` method of `dask.array`s to store the array's content into a **.zarr** file.\n",
    "    - Note: Use the argument `write_empty_chunks=False` to avoid creating files for empty chunks on disk\n",
    "- [ ] Import `ProgressBar` and use it to show the progress of the segmentation process on the whole image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yzM2YNRcAFI"
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "---\n",
    "## 5.3 Compute region properties from the stored labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Use the labels from disk instead of computing them again\n",
    "- [ ] Apply a rule to avoid computing the region properties on chunks without any labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. [Optional] Convert a regular Zarr into a OME-Zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Downsample the labels array to have a *pyramid* version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Use the labels that were stored as .zarr to create a downsampled version of the whole labeled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Bh6c9EVy9hST"
   },
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    for s in range(1, 6):\n",
    "        da_labels = da.from_zarr(\"CMU-1_Crop_labels_cellpose_cyto3.zarr\", component=str(s - 1))\n",
    "\n",
    "        da_labels_ds = da_labels[::2, ::2]\n",
    "        da_labels_ds = da_labels_ds.rechunk()\n",
    "\n",
    "        da_labels_ds.to_zarr(\n",
    "            \"CMU-1_Crop_labels_cellpose_cyto3.zarr\",\n",
    "            component=str(s),\n",
    "            write_empty_chunks=False,\n",
    "            compressor=zarr.Blosc(clevel=9),\n",
    "            overwrite=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Bh6c9EVy9hST"
   },
   "outputs": [],
   "source": [
    "z_labels = zarr.open(\"CMU-1_Crop_labels_cellpose_cyto3.zarr\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Add metadata to the `.zarr` to comply with *OME-Zarr* standard. This will enable *OME-Zarr* readers to open our `.zarr` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Bh6c9EVy9hST"
   },
   "outputs": [],
   "source": [
    "z_labels.attrs[\"multiscales\"] = [\n",
    "    {\n",
    "        \"axes\" : [\n",
    "            {\n",
    "                \"unit\" : \"millimeter\",\n",
    "                \"name\" : \"y\",\n",
    "                \"type\" : \"space\"\n",
    "            },\n",
    "            {\n",
    "                \"unit\" : \"millimeter\",\n",
    "                \"name\" : \"x\",\n",
    "                \"type\" : \"space\"\n",
    "            }\n",
    "        ],\n",
    "        \"name\" : \"Cellpose labels\",\n",
    "        \"datasets\" : [\n",
    "            {\n",
    "                \"path\" : str(s),\n",
    "                \"coordinateTransformations\": [\n",
    "                    {\n",
    "                        \"scale\" : [4.942E-4 / (2**s), 4.942E-4 / (2**s)],\n",
    "                        \"type\" : \"scale\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            for s in range(6)\n",
    "        ],\n",
    "        \"version\" : \"0.1\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "giJcwW_F3vrF"
   },
   "outputs": [],
   "source": [
    "z_labels = zarr.open(\"CMU-1_Crop_labels_cellpose_cyto3.zarr\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Visualize the segmentation labels overlayed on top of the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP3DEC9AseJB1VqZW/y5dxZ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "c86cbe32521f44e49e30d67284cb4fab": {
     "model_module": "anywidget",
     "model_module_version": "~0.9.*",
     "model_name": "AnyModel",
     "state": {
      "_anywidget_id": "vizarr._widget.Viewer",
      "_configs": [
       {
        "channel_axis": 1,
        "source": {
         "id": 0
        }
       }
      ],
      "_dom_classes": [],
      "_esm": "import * as vizarr from \"https://hms-dbmi.github.io/vizarr/index.js\";\nimport debounce from \"https://esm.sh/just-debounce-it@3\";\n\n/**\n * @template T\n * @param {import(\"npm:@anywidget/types\").AnyModel} model\n * @param {any} payload\n * @param {{ timeout?: number }} [options]\n * @returns {Promise<{ data: T, buffers: DataView[] }>}\n */\nfunction send(model, payload, { timeout = 3000 } = {}) {\n\tlet uuid = globalThis.crypto.randomUUID();\n\treturn new Promise((resolve, reject) => {\n\t\tlet timer = setTimeout(() => {\n\t\t\treject(new Error(`Promise timed out after ${timeout} ms`));\n\t\t\tmodel.off(\"msg:custom\", handler);\n\t\t}, timeout);\n\t\t/**\n\t\t * @param {{ uuid: string, payload: T }} msg\n\t\t * @param {DataView[]} buffers\n\t\t */\n\t\tfunction handler(msg, buffers) {\n\t\t\tif (!(msg.uuid === uuid)) return;\n\t\t\tclearTimeout(timer);\n\t\t\tresolve({ data: msg.payload, buffers });\n\t\t\tmodel.off(\"msg:custom\", handler);\n\t\t}\n\t\tmodel.on(\"msg:custom\", handler);\n\t\tmodel.send({ payload, uuid });\n\t});\n}\n\n/**\n * @param {import(\"npm:@anywidget/types\").AnyModel} model\n * @param {string | { id: string }} source\n */\nfunction get_source(model, source) {\n\tif (typeof source === \"string\") {\n\t\treturn source;\n\t}\n\t// create a python\n\treturn {\n\t\t/**\n\t\t * @param {string} key\n\t\t * @return {Promise<Uint8Array | undefined>}\n\t\t */\n\t\tasync get(key) {\n\t\t\tconst { data, buffers } = await send(model, {\n\t\t\t\ttype: \"get\",\n\t\t\t\tsource_id: source.id,\n\t\t\t\tkey,\n\t\t\t});\n\t\t\tif (!data.success) {\n\t\t\t\treturn undefined;\n\t\t\t}\n\t\t\treturn new Uint8Array(buffers[0].buffer);\n\t\t},\n\t};\n}\n\n/**\n * @typedef Model\n * @property {string} height\n * @property {ViewState=} view_state\n * @property {{ source: string | { id: string }}[]} _configs\n */\n\n/**\n * @typedef ViewState\n * @property {number} zoom\n * @property {[x: number, y: number]} target\n */\n\n/** @type {import(\"npm:@anywidget/types\").Render<Model>} */\nexport async function render({ model, el }) {\n\tlet div = document.createElement(\"div\");\n\t{\n\t\tdiv.style.height = model.get(\"height\");\n\t\tdiv.style.backgroundColor = \"black\";\n\t\tmodel.on(\"change:height\", () => {\n\t\t\tdiv.style.height = model.get(\"height\");\n\t\t});\n\t}\n\tlet viewer = await vizarr.createViewer(div);\n\t{\n\t\tmodel.on(\"change:view_state\", () => {\n\t\t\tviewer.setViewState(model.get(\"view_state\"));\n\t\t});\n\t\tviewer.on(\n\t\t\t\"viewStateChange\",\n\t\t\tdebounce((/** @type {ViewState} */ update) => {\n\t\t\t\tmodel.set(\"view_state\", update);\n\t\t\t\tmodel.save_changes();\n\t\t\t}, 200),\n\t\t);\n\t}\n\t{\n\t\t// sources are append-only now\n\t\tfor (const config of model.get(\"_configs\")) {\n\t\t\tconst source = get_source(model, config.source);\n\t\t\tviewer.addImage({ ...config, source });\n\t\t}\n\t\tmodel.on(\"change:_configs\", () => {\n\t\t\tconst last = model.get(\"_configs\").at(-1);\n\t\t\tif (!last) return;\n\t\t\tconst source = get_source(model, last.source);\n\t\t\tviewer.addImage({ ...last, source });\n\t\t});\n\t}\n\tel.appendChild(div);\n}\n",
      "_model_module": "anywidget",
      "_model_module_version": "~0.9.*",
      "_model_name": "AnyModel",
      "_view_count": null,
      "_view_module": "anywidget",
      "_view_module_version": "~0.9.*",
      "_view_name": "AnyView",
      "height": "500px",
      "layout": "IPY_MODEL_d5cac7167d5843308aa64fcb3f2a75df",
      "view_state": {
       "target": [
        12947.5,
        11698
       ],
       "zoom": -5.810070700295993
      }
     }
    },
    "d5cac7167d5843308aa64fcb3f2a75df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
